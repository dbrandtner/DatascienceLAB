# -*- coding: utf-8 -*-
"""Laboratorio_data_analisi.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MWKN9xisGMRYTW_zcMjQwOoX-Op0aNgb

Codice Tsne Carmine e David
"""

from google.colab import drive
drive.mount('/content/drive')

# !cp /content/drive/MyDrive/AI/kaggle.json .
# !pip install opendatasets --upgrade --quiet
import opendatasets as od

# set address to dataset to download
dataset = 'https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset'

# dowload dataset to path indicated kaggle path:
# ./stroke-prediction-dataset/healthcare-dataset-stroke-data.csv
od.download(dataset)

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# import dataset csv
name = 'stroke-prediction-dataset/healthcare-dataset-stroke-data.csv'

# construct data frame
df = pd.read_csv (name)


#######   early EDA: part1  ############
cols = df.columns
summary = df.describe(include='all')

print('\n#########  columns name:\n')
print(cols)
print('\n#########  short info columns data type:\n')
print(df.info())
print('\n#########  summary info columns distribution:\n')
print(summary)

#######   early EDA: part 2  ############

# focus on specific features:
print("\n ### smoking status label:\n")
print(df['smoking_status'].value_counts())

print("\n ### gender label:\n")
print(df['gender'].value_counts())

print("\n ### work_type label:\n")
print(df['work_type'].value_counts())

# since age range lower limit include pediatric age (0-18 years) and
# "strokes belong to the rare conditions in the pediatric population"
# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6026646/
# find how many stroke record are present in this age range

print("\n ### pediatric age records:\n")
print(df[df['age'] < 18].shape[0])

print("\n ### pediatric age strokes:\n")
print(df[(df['age'] < 18) & (df['stroke'] == 1) ].shape[0])

print("\n ### pediatric age strokes - complete features records:\n")
print(df[(df['work_type'] == "children") & (df['stroke'] == 1) ])

print("\n ### smoking_status = Unknown in pediatric age:\n")
print(df[(df['age'] < 18) & (df['smoking_status'] == "Unknown")].shape[0])

print("\n ### smoking_status = Unknown + working_type = children -> in pediatric age:\n")
print(df[(df['age'] < 18) & (df['smoking_status'] != "Unknown") & (df['work_type'] == "children")].shape[0])

print("\n ### smoking_status != Unknown -> in pediatric age:\n")
print(df[(df['age'] < 18) & (df['smoking_status'] != "Unknown")].value_counts('smoking_status'))

print("\n ### bmi = NaN -> in pediatric age:\n")
print(df[(df['age'] < 18) & (df['bmi'].isna())].shape[0])

#######   early EDA: summary and conclusions  ############

# First step for a dataset improvement resides into a modification along age:
# there is a sharp medical and socio-cultural separation bewteen
# pediatric (<18 years) and non pediatric age (>18 years).
# Although stroke could happen in pediatric age this has to be considered like
# a rare event linked prevalentely to pediatric phisiology and not affected by
# lifestyle factors like job, food intake, family and smoking behaviour.
# These lifestyle factors, indeed, carriy their effect in the long term
# of adult age. Thus it is a different picture from the dataset context
# description from Kaggle "According to the World Health Organization (WHO)
# stroke is the 2nd leading cause of death globally, responsible for
# approximately 11% of total deaths.

# Ref for pediatric phisiology differences:
# https://www.chop.edu/conditions-diseases/pediatric-stroke
# https://www.monarquehealth.com/blog/how-is-pediatric-care-different-from-working-with-adults
# https://www.cdc.gov/childrenindisasters/differences.html


# Second step for a dataset improvement is considering "bmi == NaN" and
# "smoking_status = Unknown" as suitable targets for a data cleaning
# as they represent lack of informations. For "smoking_status = Unknown" half
# of records belong to pediatric age, instead only 20 over circa 200 records
# of "bmi == NaN" belong to it.

# Third step is to evaluate gender label "Other" along "Female" and "Male" as not
# informative about the leading body phisiology or altered body phisiology
# (i.e. hormone therapy) that could be linked to strokes.
# Morevore "Other" is present in dataset as only 1 unit, therefore
# could be easely as a datset outlier.

#######   DATA CLEANING  ############

# 1. get rid of pediatric (<18 years) records
# 2. get rids of gender 'Other' (only 1 non binary Other)

df = df.loc[df['age'] >= 18]
df = df.loc[df['gender'] != "Other"]

print("\n ### entries after data cleaning 1 + 2 :\n")
print(df.shape[0])

# 3. action on smoking status (Unkwon not informative), gender (only 1 non binary Other)

df = df.loc[df['smoking_status'] != "Unknown"]

print("\n ### entries after data cleaning 3 :\n")
print(df.shape[0])

# 4. action on bmi with 4909 over 5110 entries missing NA data in original dataset

df = df.dropna(subset=['bmi'])

print("\n ### entries after data cleaning 4 :\n")
print(df.shape[0])

#######   mid EDA: part 1  ############

### Check target labels balance:
print("\n ########  Target Labels Balance:  ########  \n")
print(f"\n {df['stroke'].value_counts()}")
print(f"\nratio stroke/no stroke:\n {round(df['stroke'].value_counts()[1]/df['stroke'].value_counts()[0], 2)}")

df.info()

### Transform categorical data in continuos data:

from sklearn.preprocessing import OneHotEncoder
import pandas as pd


# Inizializzazione dell'encoder
encoder = OneHotEncoder(sparse=False)

# Lista diretta delle colonne categoriche
categorical_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']

# Verifica che tutte le colonne selezionate esistano nel DataFrame
if not all(column in df.columns for column in categorical_columns):
    missing = [column for column in categorical_columns if column not in df.columns]
    raise ValueError(f"Le colonne {missing} non sono presenti nel DataFrame.")

# Adattare e trasformare i dati categorici
encoded_data = encoder.fit_transform(df[categorical_columns])

# Usa `get_feature_names_out` per le versioni piÃ¹ recenti di scikit-learn
encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out(categorical_columns))

# Concatenare con le colonne non categoriche
final_df = pd.concat([encoded_df, df.drop(columns=categorical_columns)], axis=1)
final_df = final_df.drop(columns=['id'])

print("\n ########  Dataframe info after One Hot Encoding:  ######## \n")
final_df.info()

# eliminazione NaN prima di usare tsne
final_df = final_df.dropna()

print("\n ########  Dataframe info after NA removal:  ######## \n")
final_df.info()

### Check again target labels balance:

print("\n ########  Target Labels Balance:  ########  \n")
print(f"\n {final_df['stroke'].value_counts()}")
print(f"\nratio stroke/no stroke:\n {round(final_df['stroke'].value_counts()[1]/final_df['stroke'].value_counts()[0], 2)}")

### Correlation 1

### Try a Pearson correlation to verify which features show a real connection
### with 'stroke' target label:

import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(13,8))
# define the mask to set the values in the upper triangle to True
mask = np.triu(np.ones_like(final_df.corr(), dtype=bool))
heatmap = sns.heatmap(final_df.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':16}, pad=16);

### t-SNE 1

### Try a t-SNE to verify cluster:

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

tsne = TSNE(n_components=2, random_state=15)
#tsne = TSNE(n_components=2, random_state=15, init='random')

# apply t-SNE on vectorialized data:
tsne_results = tsne.fit_transform(final_df.iloc[:, 12:18])

# plot 2D embedding
plt.figure(figsize=(8, 8))
plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=final_df.iloc[:,-1])
plt.title('t-SNE visualization')
plt.xlabel('Componente 1')
plt.ylabel('Componente 2')
plt.show()

#####   DATASET BALANCING  ##########

from collections import Counter
from sklearn.datasets import make_classification
from imblearn.over_sampling import SMOTE
import numpy as np

#### Define your features (X) and target (y)

# features could be passed in dataframe format
X = final_df.iloc[:, 0:18]

# target labels has to be passed as numpy array
y = final_df['stroke'].astype('category')
y = y.to_numpy()

print('\n###  Original dataset shape: %s\n' % Counter(y))

# appply SMOTE oversampling technique to balance dataset:
sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)

print('\n###  Resampled dataset shape: %s\n' % Counter(y_res))

### Correlation 2

### Try a Pearson correlation to verify which features show a real connection
### with 'stroke' target label:

import matplotlib.pyplot as plt
import numpy as np

final_df_sm = X_res.assign(stroke=y_res)

plt.figure(figsize=(13,8))
# define the mask to set the values in the upper triangle to True
mask = np.triu(np.ones_like(final_df_sm.corr(), dtype=bool))
heatmap = sns.heatmap(final_df_sm.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Triangle Correlation Heatmap - after target label balancing', fontdict={'fontsize':16}, pad=16);

final_df_sm.info()

### FEATURE ENGINEEARING

# Crete a feature to express probable Metabolic Syndrome named 'MetS':
# metabolic syndrome is significantly associated with both stroke recurrence and all-cause mortality.
# Overweight (bmi >27) and diabete (avg glucose level > 140) are signature feature of MetS. Along
# this two, other conditions like high colesterol work towards a bad cardiocirculatory state.

import pandas as pd
import numpy as np
final_df_sm['MetS'] = np.where((final_df_sm['avg_glucose_level'] > 140) & (final_df_sm['bmi'] > 27), 1, 0)

### Correlation 3

### Try a Pearson correlation to verify which features show a real connection
### with 'stroke' target label:

import matplotlib.pyplot as plt
import numpy as np

plt.figure(figsize=(13,8))
# define the mask to set the values in the upper triangle to True
mask = np.triu(np.ones_like(final_df_sm.corr(), dtype=bool))
heatmap = sns.heatmap(final_df_sm.corr(), mask=mask, vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('Triangle Correlation Heatmap - after adding MetS feature', fontdict={'fontsize':16}, pad=16);

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Since that 'stroke' is at column index 18 I will not consider it for the Tsne algorithm
# Select all columns except the one at index 18
column_indexes = [i for i in range(final_df_sm.shape[1]) if i != 18]

# Apply t-SNE on the selected features, excluding 'stroke'
tsne = TSNE(n_components=2, random_state=42, perplexity=300)
tsne_results = tsne.fit_transform(final_df_sm.iloc[:, column_indexes])


plt.figure(figsize=(8, 8))
plt.scatter(tsne_results[:, 0], tsne_results[:, 1], c=y_res)  # Replace 'y_res' as needed
plt.title('t-SNE visualization')
plt.xlabel('Component 1')
plt.ylabel('Component 2')
plt.show()

from sklearn.mixture import GaussianMixture

# Assuming tsne_results is your 2D array of t-SNE transformed features
# and you want to use the same number of clusters as before (n_clusters=2)

# Initialize the Gaussian Mixture Model
n_clusters=3
gmm = GaussianMixture(n_components=n_clusters, random_state=42)

# Fit the model and predict the cluster assignments for each data point
gmm_clusters = gmm.fit_predict(tsne_results)

# Add the GMM cluster assignments to your DataFrame
final_df_sm['Cluster'] = gmm_clusters

# Visualize the clusters
plt.figure(figsize=(10, 8))
sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=gmm_clusters, palette='viridis', s=50, alpha=0.6)
plt.title('t-SNE with GMM Clusters')
plt.xlabel('t-SNE Component 1')
plt.ylabel('t-SNE Component 2')
plt.legend(title='Cluster')
plt.show()

# Assuming final_df_sm is your DataFrame and 'Cluster' column has been added from a clustering algorithm.

# Calculate the mean for each variable within each cluster
cluster_means = final_df_sm.groupby('Cluster').mean()

# Calculate the sum of the means for each variable across all clusters
cluster_sums = cluster_means.sum(axis=0)

# Calculate the relative fraction for each variable within each cluster
relative_fractions = cluster_means.div(cluster_sums, axis=1)

# Calculate the summed relative fractions for each variable across all clusters
summed_relative_fractions = relative_fractions.sum(axis=1)

# Sort the rows (clusters) based on the summed relative fractions
sorted_clusters = summed_relative_fractions.sort_values(ascending=False).index

# Reorder the rows (clusters) according to the sorted indices
sorted_relative_fractions = relative_fractions.loc[sorted_clusters]

# Now transpose the DataFrame for the heatmap
sorted_relative_fractions_transposed = sorted_relative_fractions.T

# Create the heatmap with sorted clusters
plt.figure(figsize=(10, 8))
sns.heatmap(sorted_relative_fractions_transposed, annot=True, cmap='viridis', fmt=".2f")
plt.title("Heatmap of Relative Fractions of Variable Means by Cluster, Sorted by Summed Relative Fraction")
plt.ylabel("Variable")
plt.xlabel("Cluster")
plt.show()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# split X variable Y target
X = final_df_sm.drop('stroke', axis=1)  # Features
y = final_df_sm['stroke']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Random Forest Classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit the model on the training data
rf.fit(X_train, y_train)

# Get feature importances
importances = rf.feature_importances_

# Sort the feature importances in descending order
sorted_indices = np.argsort(importances)[::-1]

# Plot the feature importances
plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[sorted_indices], align='center')
plt.xticks(range(X.shape[1]), X.columns[sorted_indices], rotation=90)
plt.ylabel('Relative Importance')
plt.show()


# Predictions on the training set
y_train_pred = rf.predict(X_train)

# Predictions on the test set
y_test_pred = rf.predict(X_test)

# Calculate metrics for the training set
train_accuracy = accuracy_score(y_train, y_train_pred)
train_precision = precision_score(y_train, y_train_pred, average='macro')
train_recall = recall_score(y_train, y_train_pred, average='macro')
train_f1 = f1_score(y_train, y_train_pred, average='macro')

# Calculate metrics for the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
test_precision = precision_score(y_test, y_test_pred, average='macro')
test_recall = recall_score(y_test, y_test_pred, average='macro')
test_f1 = f1_score(y_test, y_test_pred, average='macro')

# Print out the metrics
print("Training Metrics:")
print(f"Accuracy: {train_accuracy:.4f}")
print(f"Precision: {train_precision:.4f}")
print(f"Recall: {train_recall:.4f}")
print(f"F1 Score: {train_f1:.4f}")

print("\nTest Metrics:")
print(f"Accuracy: {test_accuracy:.4f}")
print(f"Precision: {test_precision:.4f}")
print(f"Recall: {test_recall:.4f}")
print(f"F1 Score: {test_f1:.4f}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# split X variable Y target
X = final_df_sm.drop(['stroke', 'Cluster'], axis=1)  # Features
y = final_df_sm['stroke']  # Target

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Random Forest Classifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)

# Fit the model on the training data
rf.fit(X_train, y_train)

# Get feature importances
importances = rf.feature_importances_

# Sort the feature importances in descending order
sorted_indices = np.argsort(importances)[::-1]

# Plot the feature importances
plt.figure(figsize=(10, 6))
plt.title("Feature Importances")
plt.bar(range(X.shape[1]), importances[sorted_indices], align='center')
plt.xticks(range(X.shape[1]), X.columns[sorted_indices], rotation=90)
plt.ylabel('Relative Importance')
plt.show()


# Predictions on the training set
y_train_pred = rf.predict(X_train)

# Predictions on the test set
y_test_pred = rf.predict(X_test)

# Calculate metrics for the training set
train_accuracy = accuracy_score(y_train, y_train_pred)
train_precision = precision_score(y_train, y_train_pred, average='macro')
train_recall = recall_score(y_train, y_train_pred, average='macro')
train_f1 = f1_score(y_train, y_train_pred, average='macro')

# Calculate metrics for the test set
test_accuracy = accuracy_score(y_test, y_test_pred)
test_precision = precision_score(y_test, y_test_pred, average='macro')
test_recall = recall_score(y_test, y_test_pred, average='macro')
test_f1 = f1_score(y_test, y_test_pred, average='macro')

# Print out the metrics
print("Training Metrics:")
print(f"Accuracy: {train_accuracy:.4f}")
print(f"Precision: {train_precision:.4f}")
print(f"Recall: {train_recall:.4f}")
print(f"F1 Score: {train_f1:.4f}")

print("\nTest Metrics:")
print(f"Accuracy: {test_accuracy:.4f}")
print(f"Precision: {test_precision:.4f}")
print(f"Recall: {test_recall:.4f}")
print(f"F1 Score: {test_f1:.4f}")

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
# evaluate a logistic regression model using repeated k-fold cross-validation
from sklearn.model_selection import RepeatedKFold
# for cross validation and multiple scores calculation
# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html
from sklearn.model_selection import cross_validate


# prepare the cross-validation procedure
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)

# create models
model_rfc = RandomForestClassifier(n_estimators=100, random_state=42)
model_xgb = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)

# evaluate models:
# inputs are X and y of original dataset
# function will split and CV creating 10 trained model and make 10 prediction on test part
scores_rfc = cross_validate(model_rfc, X, y, return_train_score=True, scoring=('accuracy','precision','recall','f1'), cv=cv, n_jobs=-1) #n_jobs=-1 use all processor to run in parallel
scores_xgb = cross_validate(model_xgb, X, y, return_train_score=True, scoring=('accuracy','precision','recall','f1'), cv=cv, n_jobs=-1)

from numpy import mean
from numpy import std

# report performance for Random Forest Classifier
print('\n\nRandomForestClassifier Scores with 10-fold CV:')
print('\nTrain Metrics:\n')
print('Accuracy: %.3f (%.3f)' % (mean(scores_rfc['train_accuracy']), std(scores_rfc['train_accuracy'])))
print('Precision: %.3f (%.3f)' % (mean(scores_rfc['train_precision']), std(scores_rfc['train_precision'])))
print('Recall: %.3f (%.3f)' % (mean(scores_rfc['train_recall']), std(scores_rfc['train_recall'])))
print('F1: %.3f (%.3f)' % (mean(scores_rfc['train_f1']), std(scores_rfc['train_f1'])))

print('\nTest Metrics:\n')
print('Accuracy: %.3f (%.3f)' % (mean(scores_rfc['test_accuracy']), std(scores_rfc['test_accuracy'])))
print('Precision: %.3f (%.3f)' % (mean(scores_rfc['test_precision']), std(scores_rfc['test_precision'])))
print('Recall: %.3f (%.3f)' % (mean(scores_rfc['test_recall']), std(scores_rfc['test_recall'])))
print('F1: %.3f (%.3f)' % (mean(scores_rfc['test_f1']), std(scores_rfc['test_f1'])))

# report performance XG-Boost Classifier
print('\n\nXG-Boost Classifier with 10-fold CV:')
print('\nTrain Metrics:\n')
print('Accuracy: %.3f (%.3f)' % (mean(scores_xgb['train_accuracy']), std(scores_rfc['train_accuracy'])))
print('Precision: %.3f (%.3f)' % (mean(scores_xgb['train_precision']), std(scores_rfc['train_precision'])))
print('Recall: %.3f (%.3f)' % (mean(scores_xgb['train_recall']), std(scores_rfc['train_recall'])))
print('F1: %.3f (%.3f)' % (mean(scores_xgb['train_f1']), std(scores_rfc['train_f1'])))

print('\nTest Metrics:\n')
print('Accuracy: %.3f (%.3f)' % (mean(scores_xgb['test_accuracy']), std(scores_rfc['test_accuracy'])))
print('Precision: %.3f (%.3f)' % (mean(scores_xgb['test_precision']), std(scores_rfc['test_precision'])))
print('Recall: %.3f (%.3f)' % (mean(scores_xgb['test_recall']), std(scores_rfc['test_recall'])))
print('F1: %.3f (%.3f)' % (mean(scores_xgb['test_f1']), std(scores_rfc['test_f1'])))

# print('\n RandomForestClassifier Scores with 10-fold CV:\n')
# print(scores_rfc)
# print('\n COMPLETE XG-Boost Classifier with 10-fold CV:\n')
# print(scores_xgb)
